services:
  # AI 服务
  ai-app:
    build:
      context: ./ai-service
    ports:
      - "8000:8000"
    volumes:
      - .env:/app/.env
      - ai_service_logs:/logs/ai-service
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # MongoDB 服务
  mongo:
    image: "mongo"
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_INITDB_ROOT_USERNAME}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_INITDB_ROOT_PASSWORD}
    volumes:
      - mongo_data:/data/db
    restart: always

  # Main Server 服务
  app:
    build:
      context: ./main-server
    ports:
      - "3001:3000"
    environment:
      - NODE_ENV=production
      - PORT=3000
      - ENABLE_FILE_LOGGING=true
      - LOG_LEVEL=info
      - LOG_DIR=/var/log/main-server
    env_file:
      - .env
    volumes:
      - main_server_logs:/var/log/main-server
    depends_on:
      redis:
        condition: service_started
      mongo:
        condition: service_started
      postgres:
        condition: service_started
      elasticsearch:
        condition: service_started
      ai-app:
        condition: service_healthy
    restart: always

  # Redis 服务
  redis:
    image: "redis:6.2"
    ports:
      - "6379:6379"
    environment:
      - REDIS_PASSWORD=${REDIS_PASSWORD}
    command: ["redis-server", "--requirepass", "${REDIS_PASSWORD}"]
    volumes:
      - redis-data:/data
    restart: always

  postgres:
    image: postgres:17.2-bookworm
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: always

  meme:
    image: chiwiio/meme-generator:main
    restart: always
    ports:
      - "2233:2233"

  # Elasticsearch 服务
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.13
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms2g -Xmx2g
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - xpack.security.enabled=true
      - bootstrap.memory_lock=true
      - ingest.geoip.downloader.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    restart: always

  # Logstash 服务
  logstash:
    image: docker.elastic.co/logstash/logstash:7.17.13
    environment:
      - LS_JAVA_OPTS=-Xms1g -Xmx1g
    env_file:
      - .env
    ports:
      - "5044:5044/tcp"
      - "5000:5000/tcp"
      - "9600:9600"
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml
      - ai_service_logs:/logs/ai-service
      - main_server_logs:/var/log/main-server
    depends_on:
      - elasticsearch
    restart: always

  # Kibana 服务
  kibana:
    image: docker.elastic.co/kibana/kibana:7.17.13
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - ELASTICSEARCH_USERNAME=elastic
      - ELASTICSEARCH_PASSWORD=${ELASTIC_PASSWORD}
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    restart: always

  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
      - "7334:6334"
    volumes:
      - qdrant_data:/qdrant/storage
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
      - QDRANT__SERVICE__API_KEY=${QDRANT_SERVICE_API_KEY}
    restart: always

  ai-service-arq-worker:
    build:
      context: ./ai-service
    command: bash -lc "uv run --no-sync arq app.workers.unified_worker.UnifiedWorkerSettings"
    environment:
      - REDIS_HOST=${REDIS_HOST}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - POSTGRES_HOST=${POSTGRES_HOST}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      # 记忆系统配置
      - L2_QUEUE_TRIGGER_THRESHOLD=${L2_QUEUE_TRIGGER_THRESHOLD:-10}
      - L2_FORCE_UPDATE_AFTER_MINUTES=${L2_FORCE_UPDATE_AFTER_MINUTES:-60}
      - L2_SCAN_INTERVAL_MINUTES=${L2_SCAN_INTERVAL_MINUTES:-5}
      - L2_QUEUE_MAX_LEN=${L2_QUEUE_MAX_LEN:-200}
    volumes:
      - .env:/app/.env
    depends_on:
      - redis
      - postgres
    restart: always

volumes:
  redis-data:
  mongo_data:
  postgres_data:
  elasticsearch_data:
  ai_service_logs:
  main_server_logs:
  qdrant_data:
