"""
Agent Framework ä½¿ç”¨ç¤ºä¾‹
"""

import asyncio
import logging
from typing import Dict, Any

from .adapters.model import ModelConfig, ModelProvider
from .adapters.tool import ToolFilter, ToolTag
from .core.agent import AgentConfig, create_agent
from .core.node import NodeConfig, AgentNode
from .core.orchestrator import WorkflowConfig, NodeOrchestrator, Edge
from .integration import get_framework_service

logger = logging.getLogger(__name__)


async def example_simple_agent():
    """ç®€å• Agent ç¤ºä¾‹"""
    print("=== ç®€å• Agent ç¤ºä¾‹ ===")
    
    # åˆ›å»ºæ¨¡å‹é…ç½®
    model_config = ModelConfig(
        model_id="302.ai/gpt-4o-mini",
        provider=ModelProvider.OPENAI,
        temperature=0.7
    )
    
    # åˆ›å»º Agent é…ç½®
    agent_config = AgentConfig(
        name="æµ‹è¯•åŠ©æ‰‹",
        description="æˆ‘æ˜¯ä¸€ä¸ªæµ‹è¯•ç”¨çš„AIåŠ©æ‰‹ã€‚",
        model_configs=[model_config],
        enable_memory=False
    )
    
    # åˆ›å»º Agent
    agent = create_agent("simple", agent_config)
    
    # æµ‹è¯•å¯¹è¯
    message = "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±"
    context = {"test": True}
    
    print(f"ç”¨æˆ·: {message}")
    print("åŠ©æ‰‹: ", end="", flush=True)
    
    async for chunk in agent.process_stream(message, context):
        if chunk.content:
            print(chunk.content, end="", flush=True)
    
    print("\n")


async def example_react_agent():
    """React Agent ç¤ºä¾‹"""
    print("=== React Agent ç¤ºä¾‹ ===")
    
    # åˆ›å»ºæ¨¡å‹é…ç½®
    model_configs = [
        ModelConfig(
            model_id="302.ai/gpt-4o-mini",
            provider=ModelProvider.OPENAI,
            temperature=0.7
        )
    ]
    
    # åˆ›å»ºå¸¦å·¥å…·çš„ Agent é…ç½®
    agent_config = AgentConfig(
        name="æ™ºèƒ½åŠ©æ‰‹",
        description="æˆ‘æ˜¯ä¸€ä¸ªå¯ä»¥ä½¿ç”¨å·¥å…·çš„æ™ºèƒ½åŠ©æ‰‹ã€‚",
        model_configs=model_configs,
        tool_filter=ToolFilter(enabled_only=True),
        max_iterations=3,
        enable_memory=False
    )
    
    # åˆ›å»º Agent
    agent = create_agent("react", agent_config)
    
    # æµ‹è¯•å·¥å…·è°ƒç”¨
    message = "å¸®æˆ‘æŸ¥è¯¢ä¸€ä¸‹è¿›å‡»çš„å·¨äººçš„ç›¸å…³ä¿¡æ¯"
    context = {"test": True}
    
    print(f"ç”¨æˆ·: {message}")
    print("åŠ©æ‰‹: ", end="", flush=True)
    
    async for chunk in agent.process_stream(message, context):
        if chunk.content:
            print(chunk.content, end="", flush=True)
        elif chunk.tool_call_feedback:
            print(f"\n[å·¥å…·è°ƒç”¨: {chunk.tool_call_feedback.name}]", flush=True)
    
    print("\n")


async def example_workflow():
    """å·¥ä½œæµç¤ºä¾‹"""
    print("=== å·¥ä½œæµç¤ºä¾‹ ===")
    
    # åˆ›å»ºå·¥ä½œæµé…ç½®
    workflow_config = WorkflowConfig(
        name="æµ‹è¯•å·¥ä½œæµ",
        description="ä¸€ä¸ªç®€å•çš„æµ‹è¯•å·¥ä½œæµ",
        start_node="greeting",
        end_nodes=["summary"],
        max_steps=5
    )
    
    # åˆ›å»ºç¼–æ’å™¨
    orchestrator = NodeOrchestrator(workflow_config)
    
    # åˆ›å»ºé—®å€™èŠ‚ç‚¹
    greeting_config = AgentConfig(
        name="é—®å€™åŠ©æ‰‹",
        description="æˆ‘è´Ÿè´£é—®å€™ç”¨æˆ·å¹¶äº†è§£ä»–ä»¬çš„éœ€æ±‚ã€‚",
        model_configs=[ModelConfig(
            model_id="302.ai/gpt-4o-mini",
            provider=ModelProvider.OPENAI,
            temperature=0.7
        )],
        enable_memory=False
    )
    
    greeting_agent = create_agent("simple", greeting_config)
    greeting_node = AgentNode(
        config=NodeConfig(
            node_id="greeting",
            name="é—®å€™èŠ‚ç‚¹",
            description="é—®å€™ç”¨æˆ·"
        ),
        agent=greeting_agent,
        input_transformer=lambda inp: f"è¯·é—®å€™ç”¨æˆ·å¹¶è¯¢é—®ï¼š{inp.message}"
    )
    
    # åˆ›å»ºæ€»ç»“èŠ‚ç‚¹
    summary_config = AgentConfig(
        name="æ€»ç»“åŠ©æ‰‹",
        description="æˆ‘è´Ÿè´£æ€»ç»“å¯¹è¯å†…å®¹ã€‚",
        model_configs=[ModelConfig(
            model_id="302.ai/gpt-4o-mini",
            provider=ModelProvider.OPENAI,
            temperature=0.5
        )],
        enable_memory=False
    )
    
    summary_agent = create_agent("simple", summary_config)
    summary_node = AgentNode(
        config=NodeConfig(
            node_id="summary",
            name="æ€»ç»“èŠ‚ç‚¹",
            description="æ€»ç»“å¯¹è¯"
        ),
        agent=summary_agent,
        input_transformer=lambda inp: f"è¯·æ€»ç»“ä»¥ä¸‹å¯¹è¯å†…å®¹ï¼š{inp.message}"
    )
    
    # æ·»åŠ èŠ‚ç‚¹å’Œè¾¹
    orchestrator.add_node(greeting_node)
    orchestrator.add_node(summary_node)
    orchestrator.add_edge(Edge(from_node="greeting", to_node="summary"))
    
    # æ‰§è¡Œå·¥ä½œæµ
    message = "æˆ‘æƒ³äº†è§£ä¸€äº›AIçš„çŸ¥è¯†"
    print(f"ç”¨æˆ·: {message}")
    print("å·¥ä½œæµ: ", end="", flush=True)
    
    async for chunk in orchestrator.execute_stream(message):
        if chunk.content:
            print(chunk.content, end="", flush=True)
    
    print("\n")


async def example_framework_service():
    """æ¡†æ¶æœåŠ¡ç¤ºä¾‹"""
    print("=== æ¡†æ¶æœåŠ¡ç¤ºä¾‹ ===")
    
    # è·å–æ¡†æ¶æœåŠ¡
    framework = await get_framework_service()
    
    # æµ‹è¯•ä¸åŒç±»å‹çš„ Agent
    test_cases = [
        ("simple", "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±"),
        ("react", "å¸®æˆ‘æŸ¥è¯¢ä¸€ä¸‹æœ€æ–°çš„åŠ¨æ¼«æ¨è"),
        ("bangumi", "æˆ‘æƒ³äº†è§£ã€Šé¬¼ç­ä¹‹åˆƒã€‹çš„è§’è‰²ä¿¡æ¯"),
    ]
    
    for agent_type, message in test_cases:
        print(f"\n--- æµ‹è¯• {agent_type} Agent ---")
        print(f"ç”¨æˆ·: {message}")
        print("åŠ©æ‰‹: ", end="", flush=True)
        
        context = {"test": True, "message_id": f"test_{agent_type}"}
        
        async for chunk in framework.process_with_agent(agent_type, message, context):
            if chunk.content:
                print(chunk.content, end="", flush=True)
            elif chunk.tool_call_feedback:
                print(f"\n[{chunk.tool_call_feedback.status_message}]", flush=True)
        
        print("\n")


async def run_all_examples():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("ğŸš€ Agent Framework ç¤ºä¾‹æ¼”ç¤º\n")
    
    try:
        await example_simple_agent()
        await example_react_agent()
        await example_workflow()
        await example_framework_service()
        
        print("âœ… æ‰€æœ‰ç¤ºä¾‹æ‰§è¡Œå®Œæˆï¼")
        
    except Exception as e:
        logger.error(f"ç¤ºä¾‹æ‰§è¡Œå¤±è´¥: {e}")
        print(f"âŒ ç¤ºä¾‹æ‰§è¡Œå¤±è´¥: {e}")


if __name__ == "__main__":
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )
    
    # è¿è¡Œç¤ºä¾‹
    asyncio.run(run_all_examples())